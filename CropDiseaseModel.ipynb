{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/modhudeb/CropDiseasePredictionPipeline/blob/main/CropDiseaseModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN6HY2qyxAzh"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz5mHk-Ow1go"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from skimage.feature import hog \n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJuWiP08KTS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBqPiYGs-XBj"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgiKaCYoD1Tu"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load, dump"
      ],
      "metadata": {
        "id": "oxb8d28G1zK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I6eAq_7xkJo"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS9n7VIPw7pL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/data/files/processed_images2.csv\", index_col=\"Num\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "XEdcgEGvxvkw",
        "outputId": "e89e156b-7685-48e3-ae68-5239dd868384"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3             4         5         6  \\\n",
              "Num                                                                             \n",
              "0    0.216770  0.043250  0.109301  0.021676  1.012739e-01  0.000000  0.176165   \n",
              "1    0.109492  0.000000  0.077028  0.040665  2.277621e-01  0.029686  0.129127   \n",
              "2    0.212584  0.057543  0.032233  0.055196  1.599189e-01  0.010515  0.039901   \n",
              "3    0.176282  0.022096  0.173446  0.044826  2.168921e-01  0.044826  0.042656   \n",
              "4    0.216863  0.041513  0.100990  0.023192  1.202499e-01  0.000000  0.161953   \n",
              "..        ...       ...       ...       ...           ...       ...       ...   \n",
              "715  0.000009  0.000000  0.000000  0.000000  1.214306e-07  0.000000  0.000000   \n",
              "716  0.012632  0.000000  0.000000  0.000000  2.100842e-01  0.000000  0.001204   \n",
              "717  0.156816  0.036815  0.005482  0.000000  1.467805e-01  0.000583  0.002957   \n",
              "718  0.000000  0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
              "719  0.000000  0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
              "\n",
              "            7         8         9  ...     15867     15868     15869  \\\n",
              "Num                                ...                                 \n",
              "0    0.043352  0.000000  0.216770  ...  0.212584  0.057543  0.032233   \n",
              "1    0.052214  0.025103  0.130989  ...  0.192906  0.021704  0.156403   \n",
              "2    0.043307  0.068730  0.205136  ...  0.211274  0.044598  0.112706   \n",
              "3    0.022446  0.040216  0.168091  ...  0.109145  0.000000  0.076784   \n",
              "4    0.045682  0.000000  0.216863  ...  0.077732  0.019653  0.011883   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "715  0.000000  0.000000  0.000000  ...  0.158295  0.037083  0.005522   \n",
              "716  0.000000  0.000000  0.008574  ...  0.000018  0.000000  0.000000   \n",
              "717  0.001200  0.062696  0.022366  ...  0.000018  0.000000  0.000000   \n",
              "718  0.000000  0.000000  0.000000  ...  0.002768  0.000000  0.000000   \n",
              "719  0.000000  0.000000  0.000000  ...  0.006252  0.000000  0.000000   \n",
              "\n",
              "        15870     15871     15872     15873     15874     15875  label  \n",
              "Num                                                                     \n",
              "0    0.055196  0.159919  0.010515  0.039901  0.043307  0.068730      0  \n",
              "1    0.044031  0.214981  0.044031  0.055865  0.022048  0.019751      0  \n",
              "2    0.022351  0.104429  0.000000  0.181653  0.044702  0.009996      0  \n",
              "3    0.040536  0.228748  0.029592  0.128718  0.052049  0.015957      0  \n",
              "4    0.018737  0.067252  0.000000  0.020083  0.016512  0.017371      0  \n",
              "..        ...       ...       ...       ...       ...       ...    ...  \n",
              "715  0.000000  0.147851  0.000587  0.002979  0.001209  0.062818      2  \n",
              "716  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      2  \n",
              "717  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      2  \n",
              "718  0.000000  0.018560  0.000000  0.000028  0.000000  0.000000      2  \n",
              "719  0.000000  0.043422  0.000000  0.000069  0.000000  0.000000      2  \n",
              "\n",
              "[720 rows x 15877 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05cdd55e-ea8b-4467-a9be-b18562a6dc2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>15867</th>\n",
              "      <th>15868</th>\n",
              "      <th>15869</th>\n",
              "      <th>15870</th>\n",
              "      <th>15871</th>\n",
              "      <th>15872</th>\n",
              "      <th>15873</th>\n",
              "      <th>15874</th>\n",
              "      <th>15875</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.216770</td>\n",
              "      <td>0.043250</td>\n",
              "      <td>0.109301</td>\n",
              "      <td>0.021676</td>\n",
              "      <td>1.012739e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176165</td>\n",
              "      <td>0.043352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.212584</td>\n",
              "      <td>0.057543</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.055196</td>\n",
              "      <td>0.159919</td>\n",
              "      <td>0.010515</td>\n",
              "      <td>0.039901</td>\n",
              "      <td>0.043307</td>\n",
              "      <td>0.068730</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.109492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077028</td>\n",
              "      <td>0.040665</td>\n",
              "      <td>2.277621e-01</td>\n",
              "      <td>0.029686</td>\n",
              "      <td>0.129127</td>\n",
              "      <td>0.052214</td>\n",
              "      <td>0.025103</td>\n",
              "      <td>0.130989</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192906</td>\n",
              "      <td>0.021704</td>\n",
              "      <td>0.156403</td>\n",
              "      <td>0.044031</td>\n",
              "      <td>0.214981</td>\n",
              "      <td>0.044031</td>\n",
              "      <td>0.055865</td>\n",
              "      <td>0.022048</td>\n",
              "      <td>0.019751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.212584</td>\n",
              "      <td>0.057543</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.055196</td>\n",
              "      <td>1.599189e-01</td>\n",
              "      <td>0.010515</td>\n",
              "      <td>0.039901</td>\n",
              "      <td>0.043307</td>\n",
              "      <td>0.068730</td>\n",
              "      <td>0.205136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.211274</td>\n",
              "      <td>0.044598</td>\n",
              "      <td>0.112706</td>\n",
              "      <td>0.022351</td>\n",
              "      <td>0.104429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181653</td>\n",
              "      <td>0.044702</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.176282</td>\n",
              "      <td>0.022096</td>\n",
              "      <td>0.173446</td>\n",
              "      <td>0.044826</td>\n",
              "      <td>2.168921e-01</td>\n",
              "      <td>0.044826</td>\n",
              "      <td>0.042656</td>\n",
              "      <td>0.022446</td>\n",
              "      <td>0.040216</td>\n",
              "      <td>0.168091</td>\n",
              "      <td>...</td>\n",
              "      <td>0.109145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076784</td>\n",
              "      <td>0.040536</td>\n",
              "      <td>0.228748</td>\n",
              "      <td>0.029592</td>\n",
              "      <td>0.128718</td>\n",
              "      <td>0.052049</td>\n",
              "      <td>0.015957</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.216863</td>\n",
              "      <td>0.041513</td>\n",
              "      <td>0.100990</td>\n",
              "      <td>0.023192</td>\n",
              "      <td>1.202499e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161953</td>\n",
              "      <td>0.045682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216863</td>\n",
              "      <td>...</td>\n",
              "      <td>0.077732</td>\n",
              "      <td>0.019653</td>\n",
              "      <td>0.011883</td>\n",
              "      <td>0.018737</td>\n",
              "      <td>0.067252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020083</td>\n",
              "      <td>0.016512</td>\n",
              "      <td>0.017371</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.214306e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.158295</td>\n",
              "      <td>0.037083</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.147851</td>\n",
              "      <td>0.000587</td>\n",
              "      <td>0.002979</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.062818</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>0.012632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.100842e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008574</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>0.156816</td>\n",
              "      <td>0.036815</td>\n",
              "      <td>0.005482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.467805e-01</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>0.002957</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.062696</td>\n",
              "      <td>0.022366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043422</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 15877 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05cdd55e-ea8b-4467-a9be-b18562a6dc2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05cdd55e-ea8b-4467-a9be-b18562a6dc2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05cdd55e-ea8b-4467-a9be-b18562a6dc2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCQ_96hx8T66"
      },
      "source": [
        "## data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "est_5zpAxwEP"
      },
      "outputs": [],
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(df.drop(columns='label'), df['label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OICfWCm8y4j",
        "outputId": "40b83ee1-1614-4b85-a758-a651e9c0c10f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((576, 15876), (576,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "xtrain.shape, ytrain.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84qdfsMu-T0S"
      },
      "source": [
        "# Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGjIhrio9OwJ",
        "outputId": "825a389a-aa27-4e38-cd97-63b600c07097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.12055965\n",
            "Iteration 2, loss = 0.93183140\n",
            "Iteration 3, loss = 0.78875735\n",
            "Iteration 4, loss = 0.74668682\n",
            "Iteration 5, loss = 0.56615138\n",
            "Iteration 6, loss = 0.49827884\n",
            "Iteration 7, loss = 0.39972219\n",
            "Iteration 8, loss = 0.33836960\n",
            "Iteration 9, loss = 0.26639920\n",
            "Iteration 10, loss = 0.20296994\n",
            "Iteration 11, loss = 0.17113027\n",
            "Iteration 12, loss = 0.12491875\n",
            "Iteration 13, loss = 0.09397249\n",
            "Iteration 14, loss = 0.06946987\n",
            "Iteration 15, loss = 0.04844157\n",
            "Iteration 16, loss = 0.03323547\n",
            "Iteration 17, loss = 0.02503950\n",
            "Iteration 18, loss = 0.01724083\n",
            "Iteration 19, loss = 0.01175709\n",
            "Iteration 20, loss = 0.00925518\n",
            "Iteration 21, loss = 0.00677968\n",
            "Iteration 22, loss = 0.00533990\n",
            "Iteration 23, loss = 0.00440243\n",
            "Iteration 24, loss = 0.00355055\n",
            "Iteration 25, loss = 0.00297750\n",
            "Iteration 26, loss = 0.00250406\n",
            "Iteration 27, loss = 0.00217843\n",
            "Iteration 28, loss = 0.00195651\n",
            "Iteration 29, loss = 0.00170284\n",
            "Iteration 30, loss = 0.00153082\n",
            "Iteration 31, loss = 0.00138826\n",
            "Iteration 32, loss = 0.00126737\n",
            "Iteration 33, loss = 0.00116901\n",
            "Iteration 34, loss = 0.00107972\n",
            "Iteration 35, loss = 0.00101068\n",
            "Iteration 36, loss = 0.00094353\n",
            "Iteration 37, loss = 0.00088420\n",
            "Iteration 38, loss = 0.00083876\n",
            "Iteration 39, loss = 0.00079619\n",
            "Iteration 40, loss = 0.00075751\n",
            "Iteration 41, loss = 0.00072426\n",
            "Iteration 42, loss = 0.00069390\n",
            "Iteration 43, loss = 0.00066392\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(244, 128, 64), max_iter=600, random_state=42,\n",
              "              verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nn = MLPClassifier(hidden_layer_sizes=(244,128,64,),random_state=42, verbose = True, max_iter=600)\n",
        "nn.fit(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4qq4vy8_umE",
        "outputId": "60b7dc32-4645-41b1-e0e4-50efc6457a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       184\n",
            "           1       1.00      1.00      1.00       192\n",
            "           2       1.00      1.00      1.00       200\n",
            "\n",
            "    accuracy                           1.00       576\n",
            "   macro avg       1.00      1.00      1.00       576\n",
            "weighted avg       1.00      1.00      1.00       576\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        56\n",
            "           1       0.80      0.85      0.83        48\n",
            "           2       0.87      0.82      0.85        40\n",
            "\n",
            "    accuracy                           0.86       144\n",
            "   macro avg       0.86      0.86      0.86       144\n",
            "weighted avg       0.86      0.86      0.86       144\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ypred_train = nn.predict(xtrain)\n",
        "ypred_test = nn.predict(xtest)\n",
        "\n",
        "\n",
        "rep1 = classification_report(ytrain, ypred_train)\n",
        "rep2 = classification_report(ytest, ypred_test)\n",
        "\n",
        "print(rep1)\n",
        "print(rep2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfkR3OVLBCqD"
      },
      "outputs": [],
      "source": [
        "# Support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfS43T3_DyM5",
        "outputId": "b5122cf4-af12-4ecc-8af8-4bc763db9344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(probability=True, random_state=42, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sc = SVC(degree=3,probability=True,random_state=42, verbose = True)\n",
        "sc.fit(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIMvnBVHEZwK",
        "outputId": "8c337235-a58b-440c-ccf2-72a23e3e47eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       184\n",
            "           1       0.99      0.99      0.99       192\n",
            "           2       1.00      0.97      0.99       200\n",
            "\n",
            "    accuracy                           0.99       576\n",
            "   macro avg       0.99      0.99      0.99       576\n",
            "weighted avg       0.99      0.99      0.99       576\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87        56\n",
            "           1       0.73      0.85      0.79        48\n",
            "           2       0.92      0.82      0.87        40\n",
            "\n",
            "    accuracy                           0.84       144\n",
            "   macro avg       0.85      0.84      0.84       144\n",
            "weighted avg       0.85      0.84      0.84       144\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ypred_train_ = sc.predict(xtrain)\n",
        "ypred_test_ = sc.predict(xtest)\n",
        "\n",
        "\n",
        "rep1_ = classification_report(ytrain, ypred_train_)\n",
        "rep2_ = classification_report(ytest, ypred_test_)\n",
        "\n",
        "print(rep1_)\n",
        "print(rep2_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76faS-43Hdhi"
      },
      "source": [
        "## PCA - MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4b79c8dHcp9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Bwzzv_HqM7"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=150, random_state=42)\n",
        "features = pca.fit_transform(df.drop(columns=\"label\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnzp2p-ZH9LC",
        "outputId": "5eeedede-7571-4229-a292-e5baa98992aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(720, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrn, xtst, ytrn, ytst = train_test_split(features, df[\"label\"], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "F5HIeTo5wFrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "dYBlPoVuxwwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn2 = MLPClassifier(hidden_layer_sizes=(1500,500,244,128,64),random_state=42, verbose = True, max_iter=600)\n",
        "nn2.fit(xtrn, ytrn)\n",
        "\n",
        "\n",
        "ypred_trn = nn2.predict(xtrn)\n",
        "ypred_tst = nn2.predict(xtst)\n",
        "\n",
        "\n",
        "repTr = classification_report(ytrn, ypred_trn)\n",
        "repTs = classification_report(ytst, ypred_tst)\n",
        "\n",
        "print(repTr)\n",
        "print(repTs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbNXyb_bwjP9",
        "outputId": "87c2aefc-d53a-4db7-f801-91466bcb1c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.04759647\n",
            "Iteration 2, loss = 0.74542615\n",
            "Iteration 3, loss = 0.50668061\n",
            "Iteration 4, loss = 0.30014061\n",
            "Iteration 5, loss = 0.17405671\n",
            "Iteration 6, loss = 0.11656560\n",
            "Iteration 7, loss = 0.06073990\n",
            "Iteration 8, loss = 0.03049331\n",
            "Iteration 9, loss = 0.02176798\n",
            "Iteration 10, loss = 0.00518562\n",
            "Iteration 11, loss = 0.00502656\n",
            "Iteration 12, loss = 0.00307212\n",
            "Iteration 13, loss = 0.00138807\n",
            "Iteration 14, loss = 0.00111266\n",
            "Iteration 15, loss = 0.00094964\n",
            "Iteration 16, loss = 0.00077727\n",
            "Iteration 17, loss = 0.00069398\n",
            "Iteration 18, loss = 0.00065298\n",
            "Iteration 19, loss = 0.00060171\n",
            "Iteration 20, loss = 0.00056134\n",
            "Iteration 21, loss = 0.00053774\n",
            "Iteration 22, loss = 0.00052100\n",
            "Iteration 23, loss = 0.00051066\n",
            "Iteration 24, loss = 0.00050291\n",
            "Iteration 25, loss = 0.00049739\n",
            "Iteration 26, loss = 0.00049285\n",
            "Iteration 27, loss = 0.00048897\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       184\n",
            "           1       1.00      1.00      1.00       192\n",
            "           2       1.00      1.00      1.00       200\n",
            "\n",
            "    accuracy                           1.00       576\n",
            "   macro avg       1.00      1.00      1.00       576\n",
            "weighted avg       1.00      1.00      1.00       576\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89        56\n",
            "           1       0.80      0.92      0.85        48\n",
            "           2       0.97      0.85      0.91        40\n",
            "\n",
            "    accuracy                           0.88       144\n",
            "   macro avg       0.89      0.88      0.88       144\n",
            "weighted avg       0.89      0.88      0.88       144\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppl = Pipeline([\n",
        "    (\"pca\", PCA(n_components=150, random_state=42)),\n",
        "    (\"Best_estim\", nn2)])\n",
        "ppl.fit(df.drop(columns=\"label\"), df['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hYLD-2QyeE-",
        "outputId": "7d3616b5-0294-414e-b987-86bd8e5fb72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.01583377\n",
            "Iteration 2, loss = 0.67190695\n",
            "Iteration 3, loss = 0.39826363\n",
            "Iteration 4, loss = 0.22227691\n",
            "Iteration 5, loss = 0.10272761\n",
            "Iteration 6, loss = 0.05632764\n",
            "Iteration 7, loss = 0.02559636\n",
            "Iteration 8, loss = 0.01189756\n",
            "Iteration 9, loss = 0.01099781\n",
            "Iteration 10, loss = 0.00371851\n",
            "Iteration 11, loss = 0.00257578\n",
            "Iteration 12, loss = 0.00158072\n",
            "Iteration 13, loss = 0.00100607\n",
            "Iteration 14, loss = 0.00081994\n",
            "Iteration 15, loss = 0.00077192\n",
            "Iteration 16, loss = 0.00069809\n",
            "Iteration 17, loss = 0.00062771\n",
            "Iteration 18, loss = 0.00059903\n",
            "Iteration 19, loss = 0.00057771\n",
            "Iteration 20, loss = 0.00056357\n",
            "Iteration 21, loss = 0.00055280\n",
            "Iteration 22, loss = 0.00054537\n",
            "Iteration 23, loss = 0.00053856\n",
            "Iteration 24, loss = 0.00053324\n",
            "Iteration 25, loss = 0.00052903\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('pca', PCA(n_components=150, random_state=42)),\n",
              "                ('Best_estim',\n",
              "                 MLPClassifier(hidden_layer_sizes=(1500, 500, 244, 128, 64),\n",
              "                               max_iter=600, random_state=42, verbose=True))])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppl.score(df.drop(columns=\"label\")[0:350], df['label'][0:350])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OjsmV0k2atX",
        "outputId": "56c51e66-5651-4192-bd21-a6db9ac0be42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx = ppl.predict_proba(df.drop(columns=\"label\")[0:1])\n",
        "xx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCbMNIeo50vJ",
        "outputId": "cb6bfc4b-f09a-41ca-a642-1edcb421a9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99920513e-01, 7.91511966e-05, 3.35704133e-07]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14QCU4-wNIjHtlQka8TBTVYyHsHOA2UAT",
      "authorship_tag": "ABX9TyO/FzVLq/xEQJORWi58P52j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}